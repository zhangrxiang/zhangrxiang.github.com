# server

### `Memcache`和`Redis`区别
- `Redis`中，并不是所有的数据都一直存储在内存中的，这是和`Memcached`相比一个最大的区别。
- `Redis`在很多方面具备数据库的特征，或者说就是一个数据库系统，而`Memcached`只是简单的`K/V`缓存。
- 他们的扩展都需要做集群；实现方式：`master-slave`、`Hash`。
- 在`100k`以上的数据中，`Memcached`性能要高于`Redis`。
- 如果要说内存使用效率，使用简单的`key-value`存储的话，`Memcached`的内存利用率更高，而如果`Redis`采用`hash`结构来做`key-value`存储，由于其组合式的压缩，其内存利用率会高于`Memcached`。当然，这和你的应用场景和数据特性有关。
- 如果你对数据持久化和数据同步有所要求，那么推荐你选择`Redis`，因为这两个特性`Memcached`都不具备。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择`Redis`也是明智的。
- `Redis`和`Memcache`在写入性能上面差别不大，读取性能上面尤其是批量读取性能上面`Memcache`更强

### `select`, `poll`和`epoll`的区别
#### `select`
`select`最早于1983年出现在`4.2BSD`中，它通过一个`select()`系统调用来监视多个文件描述符的数组，当`select()`返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。`select`目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，事实上从现在看来，这也是它所剩不多的优点之一。`select的`一个缺点在于**单个进程能够监视的文件描述符的数量存在最大限制**，在Linux上一般为`1024`，不过可以通过修改宏定义甚至重新编译内核的方式提升这一限制。另外，`select()`所维护的存储大量文件描述符的数据结构，随着文件描述符数量的增大，其复制的开销也线性增长。同时，由于网络响应时间的延迟 使得大量`TCP`连接处于非活跃状态，但调用`select()`会对所有`socket`进行一次线性扫描，所以这也浪费了一定的开销。
#### `poll`
`poll`在1986年诞生于`System V Release 3`，它和`select`在本质上没有多大差别，但是`poll`没有最大文件描述符数量的限制。 `poll`和`select`同样存在一个缺点就是，**包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大**。 另外，`select()`和`poll()`将就绪的文件描述符告诉进程后，如果进程没有对其进行`IO`操作，那么下次调用`select()`和`poll()`的时候将再次报告这些文件描述符，所以它们一般不会丢失就绪的消息，这种方式称为`水平触发`（`Level Triggered`）。
#### `epoll`
直到`Linux2.6`才出现了由内核直接支持的实现方法，那就是`epoll`，它几乎具备了之前所说的一切优点，被公认为`Linux2.6`下性能最好的`多路I/O`就绪通知方法。`epoll`可以同时支持`水平触发`和`边缘触发`（`Edge Triggered`，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。`epoll`同样只告知那些就绪的文件描述符，而且当我们调用`epoll_wait()`获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去`epoll`指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了`内存映射`（`mmap`）技术，这样便彻底省掉了 这些文件描述符在系统调用时复制的开销。另一个本质的改进在于`epoll`采用**基于事件**的就绪通知方式。在`select/poll`中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而`epoll`事先通过`epoll_ctl()`来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似`callback`的回调机制，迅速激活这个文件描述符，当进程调用`epoll_wait()`时便得到通知。

### `cgi`与`fastcgi`的区别
`cgi`在2000年或更早的时候用得比较多，以前`web`服务器一般只处理静态的请求，`web`服务器会根据这次请求的内容，然后会`fork`一个新进程来运行外部`c`程序 （或`perl`脚本...）， 这个进程会把处理完的数据返回给`web`服务器，最后`web`服务器把内容发送给用户，刚才`fork`的进程也随之退出。 如果下次用户还请求改动态脚本，那么`web`服务器又再次`fork`一个新进程，周而复始的进行。后来出现了一种更高级的方式是， `web`服务器可以内置`perl解释器`或`php解释器`。 也就是说这些解释器做成模块的方式，web服务器会在启动的时候就启动这些解释器。 当有新的动态请求进来时，`web`服务器就是自己解析这些`perl`或`php`脚本，省得重新`fork`一个进程，效率提高了。`fastcgi`的方式是，`web`服务器收到一个请求时，他不会重新`fork`一个进程（因为这个进程在`web`服务器启动时就开启了，而且不会退出），`web`服务器直接把内容传递给这个进程（进程间通信，但`fastcgi`使用了别的方式，`tcp`方式通信），这个进程收到请求后进行处理，把结果返回给`web`服务器，最后自己接着等待下一个请求的到来，而不是退出。 
#### `fastcgi`跟`cgi`的区别是：
在`web`服务器方面在对数据进行处理的进程方面`cgi``fork`一个新的进程进行处理读取参数，处理数据，然后就结束生命期，`fastcgi`用`tcp`方式跟远程机子上的进程或本地进程建立连接要开启`tcp`端口，进入循环，等待数据的到来，处理数据
> 服务端现在有个`10万`个字单词， 客户每次会发来一个字符串，问以这个字符串为前缀的单词有多少个。 那么可以写一个程序，这个程序会建一棵`trie`树，然后每次用户请求过来时可以直接到这个`trie`去查找。 但是如果以`cgi`的方式的话，这次请求结束后这课`trie`也就没了，等下次再启动该进程时，又要新建一棵`trie`树，这样的效率就太低下了。而用`fastcgi`的方式的话，这课`trie`树在进程启动时建立，以后就可以直接在`trie`树上查询指定的前缀了。

### `Apache`与`Nginx`的优缺点比较 
#### `nginx`相对于`apache`的优点： 
轻量级，比`apache`占用更少的内存及资源。高度模块化的设计，编写模块相对简单抗并发，`nginx`处理请求是`异步非阻塞`，多个连接（万级别）可以对应一个进程，而`apache` 则是`阻塞型`的，是`同步多进程模型`，一个连接对应一个进程，在高并发下nginx 能保持低资源低消耗高性能`nginx`处理静态文件好，`Nginx`静态处理性能比`Apache`高3倍以上 
#### `apache` 相对于`nginx` 的优点： 
`apache` 的`rewrite` 比`nginx` 的`rewrite` 强大 ，模块非常多，基本想到的都可以找到 ，比较稳定，少bug ，nginx`的bug相对较多 
> 原因：这得益于`Nginx`使用了最新的`epoll`（`Linux 2.6内核`）和`kqueue`（`freebsd`）网络`I/O`模型，而`Apache`则使用的是传统的`select`模型。目前`Linux`下能够承受高并发访问的 `Squid`、`Memcached`都采用的是`epoll`网络`I/O`模型。 处理大量的连接的读写，`Apache`所采用的`select`网络`I/O`模型非常低效。